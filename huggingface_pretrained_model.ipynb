{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a94c398e",
   "metadata": {},
   "source": [
    "# Get Huggingface pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d8794b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 21.1.3; however, version 21.2.4 is available.\r\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_latest_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a1f2c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import torch\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7665be",
   "metadata": {},
   "source": [
    "## Get pretrained model, test and save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "739437a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2884001c56c047fb90a98cbced3b5c4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c17769852e83462d8e70a3889b2524c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26a3e8829a3340a4b8df5118b230e228",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "124a9a9881a549688772218c79c8602c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pretrained_classifier = pipeline(\"sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0dd40eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9998599290847778},\n",
       " {'label': 'NEGATIVE', 'score': 0.9997907280921936}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_classifier([\n",
    "    \"I really like this place!\",\n",
    "    \"The food was bad!\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4fecd119",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_classifier.save_pretrained(\"./model/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3925fc0",
   "metadata": {},
   "source": [
    "## Check if we can successfully load our saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "832adafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_classifier = pipeline('sentiment-analysis', model=\"./model/\", tokenizer=\"./model/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b167a265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9998599290847778},\n",
       " {'label': 'NEGATIVE', 'score': 0.9997907280921936}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_classifier([\n",
    "    \"I really like this place!\",\n",
    "    \"The food was bad!\"\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319f977f",
   "metadata": {},
   "source": [
    "ok this works!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff43615",
   "metadata": {},
   "source": [
    "## Build container for Lambda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2500732",
   "metadata": {},
   "source": [
    "Let's build a container that holds our huggingface model \n",
    "and our lambda code that handles requests and forwards the data to our huggingface model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3be8179e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "look at the versions for our dependencies:\n",
      "\n",
      "Python 3.6.13\n",
      "Torch version 1.7.1\n",
      "Transformers version 4.9.2\n"
     ]
    }
   ],
   "source": [
    "print(\"look at the versions for our dependencies:\")\n",
    "print(\"\")\n",
    "!python --version\n",
    "print(f\"Torch version {torch.__version__}\")\n",
    "print(f\"Transformers version {transformers.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac1b358",
   "metadata": {},
   "source": [
    "### Create requirements.txt with dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f1436a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile requirements.txt\n",
    "--find-links  https://download.pytorch.org/whl/torch_stable.html \n",
    " \n",
    "torch==1.7.1+cpu\n",
    "transformers==4.9.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30845ea1",
   "metadata": {},
   "source": [
    "### Create dockerfile\n",
    "https://docs.aws.amazon.com/lambda/latest/dg/images-create.html\n",
    "\n",
    "- start from the official lambda docker container.\n",
    "- copy the requirements.txt to the docker container and isntall.\n",
    "- copy our model we saved locally in the model/ folder to the docker container\n",
    "- execcute the lambda handler function on start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c921e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile Dockerfile\n",
    "FROM public.ecr.aws/lambda/python:3.8\n",
    "\n",
    "COPY requirements.txt ./requirements.txt\n",
    "RUN pip install -r requirements.txt \n",
    "\n",
    "COPY ./model/   ./model/\n",
    "COPY ./app/app.py   ./\n",
    "CMD [\"app.handler\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120f7358",
   "metadata": {},
   "source": [
    "### Build dockerfile and push to ECR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1f3668e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 21.1.3; however, version 21.2.4 is available.\r\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_latest_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install sagemaker-studio-image-build --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba30f1fb",
   "metadata": {},
   "source": [
    "make sure this role has a trust relationship with codebuild\n",
    "\n",
    "https://github.com/aws-samples/sagemaker-studio-image-build-cli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04dcfc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sm-docker build . --repository huggingface-on-lambda:1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3174d981",
   "metadata": {},
   "source": [
    "## Deploy Container within a Lambda Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fd7f0b",
   "metadata": {},
   "source": [
    "Create a serverless.yml file that points to the docker image uri + digest.\n",
    "\n",
    "We expect a POST request on the path \"prediction/\"\n",
    "\n",
    "More configuration can be found in the serverless file ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c9ddcbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCOUNT_NUMBER = \"\"\n",
    "REGION = \"\"\n",
    "# {ACCOUNT_NUMBER}.dkr.ecr.{REGION}.amazonaws.com/huggingface-on-lambda\n",
    "image_uri= \"\"\n",
    "# sha256:f0e2ae3aee2cceb6d93d...\n",
    "image_digest = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9eab2d",
   "metadata": {},
   "source": [
    "__serverless file__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4c2af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"\n",
    "service: huggingface-on-lambda\n",
    "\n",
    "provider:\n",
    "  name: aws\n",
    "  region: eu-west-1 \n",
    "\n",
    "functions:\n",
    "  huggingface:\n",
    "    image: {image_uri}@{image_digest}\n",
    "    # 2 minutes before we throw a timeout\n",
    "    timeout: 120\n",
    "    # have 1 hot lambda available\n",
    "    provisionedConcurrency: 1\n",
    "    # our model is less than 1GB, so 1024MB is enough\n",
    "    memorySize: 1024 \n",
    "    events:\n",
    "      - http:\n",
    "          path: prediction\n",
    "          method: post\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085297e0",
   "metadata": {},
   "source": [
    "open an AWS cloudshell and install the serverless framework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc460e5",
   "metadata": {},
   "source": [
    "    npm install serverless"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38145d60",
   "metadata": {},
   "source": [
    "create the serverless.yml file in the cloudshell\n",
    "    \n",
    "    cat > serverless.yml\n",
    "\n",
    "paste the contents and press ctrl + c to close and save the file.\n",
    "To deploy the stack run\n",
    "\n",
    "    npm install --prefix ./ serverless\n",
    "    node_modules/serverless/bin/serverless.js deploy\n",
    "    \n",
    "    \n",
    "            Output:\n",
    "    \n",
    "            Serverless: Packaging service...\n",
    "            Serverless: WARNING: Function huggingface has timeout of 120 seconds, however, \n",
    "            it's attached to API Gateway so it's automatically limited to 30 seconds.\n",
    "            Serverless: Uploading CloudFormation file to S3...\n",
    "            Serverless: Uploading artifacts...\n",
    "            Serverless: Validating template...\n",
    "            Serverless: Updating Stack...\n",
    "            Serverless: Checking Stack update progress...\n",
    "            ........................\n",
    "            Serverless: Stack update finished...\n",
    "            Service Information\n",
    "            service: huggingface-on-lambda\n",
    "            stage: dev\n",
    "            region: eu-west-1\n",
    "            stack: huggingface-on-lambda-dev\n",
    "            resources: 12\n",
    "            api keys:\n",
    "              None\n",
    "            endpoints:\n",
    "              POST - https://8af9ar02gi.execute-api.eu-west-1.amazonaws.com/dev/prediction\n",
    "            functions:\n",
    "              huggingface: huggingface-on-lambda-dev-huggingface\n",
    "            layers:\n",
    "              None\n",
    "            Serverless: Removing old service artifacts from S3...\n",
    "\n",
    "if deploy succeeds, call the endpoint\n",
    "\n",
    "    curl -d '{\"data\":\"some very much wow positive text!\"}' -H \"Content-Type: application/json\" -X POST https://8af9ar02gi.execute-api.eu-west-1.amazonaws.com/dev/prediction\n",
    "            \n",
    "            Output:\n",
    "            \n",
    "            [{\"label\": \"POSITIVE\", \"score\": 0.9998674392700195}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74202496",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_latest_p36",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
